# Tack Prediction

A marine electronics company that produces hardware and software for sailing yachts, installed some sensors on one of the boats and provided the dataset they have collected. 

We analyse the data in order to give the client some feedback on data collection and handling process, and suggest some ideas of how this data can be used to enhance their product and make it more popular among professional sailors and boat manufacturers. In particular, we are interested in 'tack prediction'. "A tack is a specific maneuver in sailing and alerting the sailor of the necessity to tack in the near future would bring some advantage to them compared to other sailors, who would have to keep an eye out on the conditions all the time to decide when to tack." We build a forecasting model that would be alerting sailors of the tacking event happening ahead.

In exploratory_data_analysis.py, we perform exploratory data analysis (EDA) and generate plots which are stored in the 'plots' folder. The EDA also informs us of feature engineering strategy, e.g. convert some angles to sines and cosines, and some to the principal value (between -180 deg and 180 deg). fix_window_forecast.py is for experimentation only; disregard.

For tack prediction, we use rolling window forecasting with a 18 hour training window and 12 hour validation/prediction windows. From our EDA, we first select a limited number of features (with their lags) for our tack prediction models. In rolling_forecast_model_selection.py, we perform data preprocessing, feature engineering, and perform rolling forecast. We use logistic regression, XGBoost Classifier and an LSTM neural network, and find that logistic regression (C=0.1) performs best, as measured by F_beta scores with beta = 1, 2, 0.5, with very modest resource requirements and training time. 

In rolling_forecast_feature_selection.py, we explore feature selection and their lag features, and evaluate different choices by F_beta scores, the confusion matrix, the precision score and the recall score. It turns out that, for best performance, it is important to include most of the given features, except for DateTime, latitude, longitude and rudder angle ('RudderAng'). As for the lag features, the F_1 and F_0.5 scores are highest if we include lag 1 second features, while the F_2 score is highest including features at lag 1 second and 2 seconds. We also find that the precision score decreases with the number of lags included, while the opposite is true for the recall score. 

All in all, the best validation set scores are : F_1: 0.366, F_2: 0.441, F_0.5: 0.314, precision: 0.287, recall: 0.535. Our model in general gives higher recall that precision, i.e. more false positives than false negatives. Re-training the logistic regression model each time only takes less than 2 seconds on the local machine. The low computation costs make it suitable for deployment on a boat where the onboard computational power and Internet access is limited.

Note that we advise that we not use lag features of the target label ('Tacking'), as this would be like having a human sailing instructor onboard telling us when to tack, which the machine takes as input to decide whether it should tell you also to tack. Indeed, we find that including such feature would make our machine learning model almost perfect. But it defeats the purpose: our goal is to build a model that tells us when to tack, without human intervention.

rolling_forecast_master.py is the final script to be used for model deployment.
